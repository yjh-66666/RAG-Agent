# 大模型应用开发实习｜面试问题指南（结合你的 RAG 项目）

> 目标：把你这个项目讲清楚、讲真实、讲到“像做过线上服务”的程度。
> 
> 适用：北京中厂（大模型应用/后端/平台）实习。

---

## 0. 30 秒项目自我介绍（建议背熟）

我做了一个企业知识库问答服务，核心是 RAG：把公司文档（txt/pdf/docx）解析切分后写入 Chroma 向量库，查询时先做 TopK 检索，再把命中的片段拼成上下文交给 DeepSeek 生成答案，同时返回引用来源。服务端用 FastAPI 提供 `/ingest`、`/search`、`/agent_chat` 等接口；支持 JWT/API Key 鉴权、按角色/部门过滤、审计日志落盘，并用 Prometheus 暴露延迟、空召回、LLM 耗时和 token 等指标。

---

## 1. 项目详细介绍（按模块讲，不要按代码行号讲）

### 1.1 系统架构与数据流

- **离线入库（ingest）**
  - 读取文件（PDF/DOCX/TXT）→ 计算 hash/mtime → 写入文档元信息（document_id、权限、部门等）
  - 文本切分：`chunk_size/chunk_overlap`
  - 本地 embedding：优先加载本地 BGE；加载失败则降级为轻量 embedding（保证流程可跑）
  - 写入 Chroma：持久化到 `./chroma_db`
  - 保存元数据：`./metadata_db/metadata.json` + 审计 `audit_logs.jsonl`

- **在线查询（search / agent_chat）**
  - query embedding → 向量检索 topk（实际取 `k*3` 做二次筛选）
  - 权限过滤：`access_control` vs `roles`，部门过滤：`department`
  - freshness 加权：根据 `last_modified/upload_time` 调整排序
  - RAG 生成：拼接上下文 → DeepSeek 生成回答 → 返回 answer + sources

### 1.2 你实现了哪些“企业级特性”

- **鉴权**：JWT / API Key 两种模式；Swagger 支持 Authorize。
- **权限**：角色与部门过滤，避免越权读取。
- **审计**：关键操作落盘，方便追责与排查。
- **可观测性**：Prometheus 指标（接口延迟/成功率 + RAG 质量/成本指标）。

### 1.3 监控指标（你可以当加分点讲）

你项目里现在至少能在 `/metrics` 看到：
- **接口层**：`rag_request_latency_seconds`、`rag_requests_total`
- **RAG 质量**：
  - `rag_empty_retrieval_total`：空召回次数（按 endpoint/department）
  - `rag_retrieval_docs_count`：每次检索命中 doc/chunk 数分布
  - `rag_retrieval_similarity_score`：相似度分布
- **LLM 成本/性能**：
  - `rag_llm_latency_seconds`：LLM 调用耗时
  - `rag_llm_tokens_total`：token 用量（能取到就记，取不到不影响运行）

> 你可以强调：这些指标的目的，是让你能回答“质量/成本怎么监控、怎么定位退化”。

---

## 2. 简历怎么写（更像中厂风格，避免“AI味儿”）

### 2.1 项目名称（建议）
企业知识库问答系统（RAG + Agent + 权限 + 监控）

### 2.2 技术栈
Python / FastAPI / LangChain / Chroma / Sentence-Transformers(BGE) / DeepSeek(OpenAI兼容) / JWT / Prometheus

### 2.3 简历描述（可直接用）
- 搭建企业知识库 RAG 服务：支持文档解析入库、向量检索、基于检索上下文的问答生成，并返回可追溯引用来源。
- 实现 JWT/API Key 鉴权与角色/部门访问控制，配套审计日志记录关键操作。
- 建立 Prometheus 可观测性：请求延迟/错误率 + 空召回、检索得分分布、LLM 耗时与 token 用量等指标，用于线上质量与成本监控。

### 2.4 你需要准备的“量化信息”（面试必问）
你至少要能说清楚下面这些数字（先跑一遍 demo，记下来）：
- **文档量**：导入了多少份文档
- **chunk 数**：切分后多少 chunk
- **耗时**：一次 ingest 大约多久；一次 agent_chat P50/P95 多少
- **空召回比例**：在一组测试问题上空召回占比

如果暂时没压测，也可以说：目前 demo 规模下的量级，后续计划用 locust/ab 做压测。

---

## 3. 面试高频问答（含“更像人说话”的回答方式）

> 原则：回答尽量用“我怎么做的 + 为什么这么做 + 现在的限制 + 后续怎么改”。

### Q1：你这个项目解决什么问题？
**答法**：
企业知识沉淀在文档里，靠人工搜索效率低。我做的是一个知识库问答服务：先把文档入库向量化，查询时用检索结果作为上下文，让模型在“可追溯证据”上回答，避免纯聊天瞎编。

### Q2：RAG 的链路你能从头讲一遍吗？
**答法**：
入库：加载文档 → 切 chunk → embedding → 写 Chroma；
查询：对问题做 embedding → topk 检索 → 过滤权限/部门 → freshness 调整 → 拼上下文 → 调 DeepSeek → 返回答案和来源。

### Q3：为什么要切分 chunk？chunk_size/overlap 怎么选？
**答法**：
不切分的话文档太长，模型上下文放不下，而且检索粒度很粗。chunk_size 太大噪声多、太小语义断裂；overlap 是为了跨段信息不断。我目前是偏经验值，后续会用评测集对 chunk 参数做对比。

### Q4：你怎么做权限控制？有没有风险？
**答法**：
我在文档 metadata 里写 `access_control` 和 `department`，检索后做过滤，避免越权返回片段。风险是“后过滤”会浪费计算、也可能有侧信道，进一步可以把权限前移到向量库层（metadata filter）或者分 collection。

### Q5：为什么 embedding 本地，LLM 用 API？
**答法**：
embedding 是固定模型，适合本地化，成本低也更可控；LLM 能力迭代快，用 API 更省维护。查询时只把命中的片段发给模型，不直接上传全库数据。

### Q6：检索质量怎么评估？你怎么知道它退化了？
**答法**：
离线我会准备一小套问题-命中文档的评测集，算 topk 命中率；在线用指标监控：空召回比例、得分分布是否漂移、命中 chunk 数是否异常。现在我已经把空召回、得分分布、LLM 耗时/Token 暴露到 Prometheus，至少能先发现问题。

### Q7：为什么 sources 会重复？你会怎么优化？
**答法**：
因为检索是按 chunk 返回，同一文件多个 chunk 都可能进 topk。优化可以按文件聚合去重，或者用 MMR 降冗余，再把多 chunk 合并成更可读的引用。

### Q8：如何防 Prompt Injection 或敏感信息泄露？
**答法**：
我对输入做了规则检测（典型“忽略指令/泄露 key”等），命中就拒答并记录审计。更稳妥的话还应该对输出再做一次敏感信息扫描，并且把工具调用严格限制在白名单。

### Q9：线上成本怎么控？
**答法**：
主要是减少不必要的 LLM 调用、缩短上下文和缓存：
- 先检索再决定要不要调用 LLM（空召回直接拒答）
- 控制 topk 与上下文长度
- 对高频 query 做缓存
- 监控 token 用量和 P95 耗时，找到异常请求。

### Q10：你系统里最需要改进的地方是什么？
**答法**：
最关键是检索质量和数据治理：增量更新、删除、重复入库的幂等；再加混合检索/重排提升召回与排序。现在是 demo 到可用服务的阶段，结构已经搭好，后续就是把策略做扎实。

---

## 4. 面试准备流程（按 3~7 天规划）

### 4.1 第 1 天：把项目跑顺 + 录屏
- 你能在 3 分钟内演示：
  - `/auth/dev_login` → Swagger Authorize
  - `/ingest` 导入 demo_docs
  - `/agent_chat` 问答返回 sources
  - `/metrics` 展示延迟/空召回/LLM 耗时

### 4.2 第 2-3 天：准备“可量化数据”
- 导入多少文档/多少 chunk
- 10~30 条测试问题，统计空召回比例
- 记录一次查询的端到端耗时

### 4.3 第 4-5 天：补齐大模型应用基础知识
- RAG：chunk、overlap、topk、MMR、rerank、混合检索
- 向量库：索引、持久化、增量更新、metadata filter
- 安全：注入、越权、脱敏、审计
- 工程：限流/超时/重试/熔断、观测（指标/日志/追踪）

### 4.4 第 6-7 天：模拟面试
- 用本文件的问题随机抽 10 个，要求“2 分钟内说清楚”
- 每个问题都准备：当前实现 → 风险点 → 可改进方向

---

## 5. 面试时你要带的材料清单

- **简历 PDF**（项目描述统一口径）
- **项目演示脚本**（上面 3 分钟流程）
- **一页架构图**（可手绘：ingest/检索/LLM/鉴权/监控）
- **一页指标截图**（/metrics 或 Grafana 截图都行）
- **（可选）评测表格**：10~30 条问题命中情况

---

## 6. 你现在这个项目里“不要在面试里吹”的点（避免被追问穿）

- “异步任务处理/容器化支持/检索缓存”等，如果你代码里没做，不要主动写成已实现。
- 成本优化、限流熔断、Rerank 等可以说成“下一步计划”。

---

## 7. 你可以主动加分的说法（建议）

- 我不是只把 RAG 跑通，而是补了鉴权、审计、监控，能解释上线后怎么观察质量退化、怎么定位问题。
- 我会用小评测集做参数对比，而不是靠直觉调 chunk/topk。

